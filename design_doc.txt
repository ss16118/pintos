            +----------------------+
            |        OS 211        |
            |  TASK 1: SCHEDULING  |
            |    DESIGN DOCUMENT   |
            +----------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, or notes for the
>> markers, please give them here.

>> Please cite any offline or online sources you consulted while preparing your 
>> submission, other than the Pintos documentation, course text, lecture notes 
>> and course staff.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> A1: (2 marks) 
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration.  
>> Identify the purpose of each in roughly 25 words.

>> A2: (4 marks) 
>> Draw a diagram that illustrates a nested donation in your structure and 
>> briefly explain how this works.

---- ALGORITHMS ----

>> A3: (3 marks) 
>> How do you ensure that the highest priority waiting thread wakes up first for
>> a (i) lock, (ii) semaphore, or (iii) condition variable?

>> A4: (3 marks)
>> Describe the sequence of events when a call to lock_acquire() causes a 
>> priority donation. 
>> How is nested donation handled?

>> A5: (3 marks)
>> Describe the sequence of events when lock_release() is called on a lock that 
>> a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> A6: (2 marks)
>> How do you avoid a race condition in thread_set_priority() when a thread 
>> needs to recompute its effective priority, but the donated priorities 
>> potentially change during the computation?
>> Can you use a lock to avoid the race?

---- RATIONALE ----

>> A7: (3 marks)
>> Why did you choose this design?  
>> In what ways is it superior to another design you considered?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> B1: (2 marks)
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration. 
>> Identify the purpose of each in roughly 25 words.

1. new struct member:

struct thread
  {
    /* Owned by thread.c. */
    tid_t tid;                          /* Thread identifier. */
    enum thread_status status;          /* Thread state. */
    char name[16];                      /* Name (for debugging purposes). */
    uint8_t *stack;                     /* Saved stack pointer. */
    int priority;                       /* Base Priority. */
    int effective_priority;             /* Effective Priority. */
    struct list_elem allelem;           /* List element for all threads list. */

    /* Shared between thread.c and synch.c. */
    struct list_elem elem;              /* List element. */
    struct thread *dependent_on;        /* Pointer of thread this thread
                                           is dependent on */

    struct list_elem dependent_elem;    /* List element for dependent list */
    struct list dependent_list;         /* List of threads dependent on this thread */
--> int nice;                           /* Nice value of the thread*/
--> int64_t recent_cpu;                 /* recent_cpu value of the thread */

#ifdef USERPROG
    /* Owned by userprog/process.c. */
    uint32_t *pagedir;                  /* Page directory. */
#endif

    /*
     * Owned by timer.c to determine whether the thread is sleeping and
     * how long the thread needs to sleep for
     */
    int64_t wake_time;

    /* Owned by thread.c. */
    unsigned magic;                     /* Detects stack overflow. */
  };

2.static variable:

static int64_t load_average = 0;


static int64_t load_average = 0;  /* defined in thread.c */

int nice, int64_t recent_cpu are added to struct thread for the
advanced scheduler.

int nice is used to store the niceness of the thread, whereas recent_cpu stores
the thread's cpu_usage. Both attributes are used in the calculation of priority.

load_average is a static variable that estimates the average number of threads
that are running or ready threads in the past 60 seconds. It is used in the 
calculation of recent_cpu.

recent_cpu and load_average are real numbers. To minimize rounding error, they
are stored as 2 ^ 14 multiplied by their actual value. 
Conversion back to their actual value only happens when their values
are retrieved by the get functions.

We have not used any additional data_structure to store the threads. They are
still kept in the ready_list which is sorted every time priority is updated.

---- ALGORITHMS ----

>> B2: (3 marks)
>> Suppose threads A, B, and C have nice values 0, 1, and 2 and each has a 
>> recent_cpu value of 0. 
>> Fill in the table below showing the scheduling decision, the priority and the
>> recent_cpu values for each thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0    	0	 0	 0	 31	 29	 27	     A	
 4		  4	 0 	 0	 30	 29	 27	     A
 8		  8	 0	 0	 29	 29	 27	     A
12		 12	 0	 0	 28	 29	 27	     B
16	 	 12	 4	 0	 28	 28	 27	     A
20		 16	 4	 0	 27	 28	 27	     B
24		 16	 8	 0	 27	 27	 27	     A
28		 20	 8	 0	 26	 27	 27	     B
32		 20	12	 0	 26	 26	 27	     C
36		 20	12	 4	 26	 26	 26	     A

>> B3: (2 marks) 
>> Did any ambiguities in the scheduler specification make values in the table 
>> uncertain? 
>> If so, what rule did you use to resolve them?

When two threads have the same priority, the scheduler's behaviour is undefined
by the specification. In our implementation, when two threads have the same
priority, their relative position in the ready_list is kept unchanged. 
This means that the scheduler will keep the current thread running.
As a result, the cost of swapping running thread is minimized.

---- RATIONALE ----

>> B4: (3 marks)
>> Briefly critique your design, pointing out advantages and disadvantages in 
>> your design choices.

We use one queue (the ready_list) rather than 64 lists to store the threads. 
There are two major advantages in this design. Firstly, the design uses
less memory, since no additional list data structure is used to store the
threads. Secondly, when there are few threads in the ready_list, the program
runs faster as there is no need to traverse through all 64 lists.

However, when the number of threads increases, our design becomes
less efficient. That is because the ready_list needs to be sorted every time the
priority is updated (this operation has complexity O(nlogn)).
Carrying out such an expensive operation every 4 ticks (0.04s) causes
the program to get slower.
